{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1eda33-4804-42dd-b0b9-12a49a29a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from model import QNetwork\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fe8807-2cb3-4569-97f9-8b04b74e9b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/Users/nathan/Documents/Learning/Udacity_deepRL/Value-based-methods/p1_navigation/Banana.app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366af856-14a3-411f-9f62-04e0de2b8c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 16.89\n",
      "Episode 200\tAverage Score: 15.78\n",
      "Episode 300\tAverage Score: 15.77\n",
      "Episode 400\tAverage Score: 16.38\n",
      "Episode 500\tAverage Score: 15.32\n"
     ]
    }
   ],
   "source": [
    "from agent import DemoAgent\n",
    "\n",
    "agent = DemoAgent(37, 4, 0, 'checkpoint_magic-violet-19.pth')\n",
    "\n",
    "brain_name = env.brain_names[0] \n",
    "brain = env.brains[brain_name] \n",
    "env_info = env.reset(train_mode=True)[brain_name] # Train mode is fast moving\n",
    "\n",
    "num_episodes = 500 \n",
    "max_timesteps = 500 \n",
    "scores = []\n",
    "scores_window = deque(maxlen=100)\n",
    "\n",
    "for episode_num in range(1, num_episodes+1):\n",
    "    score = 0\n",
    "    # reset environment \n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    \n",
    "    for timestep in range(max_timesteps):\n",
    "        # Choose an action based on an inference \n",
    "        state = env_info.vector_observations[0]\n",
    "        action = agent.act(state) \n",
    "\n",
    "        # Apply action to the environment and get the results \n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                   \n",
    "\n",
    "        state = next_state\n",
    "        score += reward      \n",
    "        if done:\n",
    "            break    \n",
    "    \n",
    "    scores_window.append(score)  # Save the most recent score \n",
    "    scores.append(score) \n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode_num, np.mean(scores_window)), end=\"\")\n",
    "    if episode_num % 100 == 0:\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode_num, np.mean(scores_window)))\n",
    "\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c924b-1ae8-4a58-b5f5-876f4f3ba6b0",
   "metadata": {},
   "source": [
    "neat-fog-17\n",
    "    Episode 100\tAverage Score: 13.14\n",
    "    Episode 200\tAverage Score: 13.55\n",
    "    Episode 300\tAverage Score: 14.11\n",
    "    Episode 400\tAverage Score: 13.93\n",
    "    Episode 500\tAverage Score: 13.89\n",
    "    \n",
    "magic-violet-19\n",
    "    Episode 100\tAverage Score: 16.89\n",
    "    Episode 200\tAverage Score: 15.78\n",
    "    Episode 300\tAverage Score: 15.77\n",
    "    Episode 400\tAverage Score: 16.38\n",
    "    Episode 500\tAverage Score: 15.32\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
